<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Sriram Rampelli – AI Engineer Portfolio</title>
  <!-- Google Font for a modern, clean look -->
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap" rel="stylesheet">
  <style>
    /* Root variables for a cohesive, “magical” palette */
    :root {
      --primary-color: #4b6cb7;
      --secondary-color: #182848;
      --accent-color: #ff9a9e;
      --light-gray: #f3f4f6;
      --dark-gray: #333;
      --card-bg: #ffffff;
      --shadow-color: rgba(0, 0, 0, 0.1);
    }

    /* Global reset and typography */
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }
    html {
      scroll-behavior: smooth;
    }
    body {
      font-family: 'Poppins', sans-serif;
      line-height: 1.6;
      color: var(--dark-gray);
      background: var(--light-gray);
    }
    a {
      color: var(--primary-color);
      text-decoration: none;
      transition: color 0.2s;
    }
    a:hover {
      color: var(--accent-color);
    }
    h1, h2, h3, h4 {
      color: var(--secondary-color);
      margin-bottom: 0.5rem;
      line-height: 1.2;
    }
    p {
      margin-bottom: 1rem;
    }

    /* Smooth section spacing */
    section {
      padding: 4rem 2rem;
      position: relative;
    }
    /* Add subtle fade-in on scroll */
    section {
      opacity: 0;
      transform: translateY(20px);
      transition: opacity 0.6s ease-out, transform 0.6s ease-out;
    }
    section.visible {
      opacity: 1;
      transform: translateY(0);
    }

    /* Hero section with gradient background */
    .hero {
  text-align: center;
  padding: 6rem 2rem 8rem;      /* <-- added extra bottom padding (8rem) */
  background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
  color: #fff;
  border-bottom-left-radius: 50% 10%;
  border-bottom-right-radius: 50% 10%;
  margin-bottom: 3rem;
  position: relative;
  overflow: hidden;
}
    .hero h1 {
      font-size: 3rem;
      margin-bottom: 1rem;
      font-weight: 700;
    }
    .hero p {
      font-size: 1.1rem;
      max-width: 600px;
      margin: 0 auto 1.5rem;
    }
    .hero .btn {
  background: #fff;
  color: var(--secondary-color);
  font-weight: 600;
  padding: 0.75rem 1.5rem;
  border-radius: 30px;
  box-shadow: 0 4px 10px var(--shadow-color);
  transition: background 0.2s, color 0.2s, transform 0.2s;
  margin-top: 2rem;             /* <-- ensure the button sits lower */
}
    .hero .btn:hover {
      background: var(--accent-color);
      color: #fff;
      transform: translateY(-2px);
    }

    /* Container to center content */
    .container {
      max-width: 960px;
      margin: 0 auto;
    }

    /* Section titles */
    h2 {
      font-size: 2rem;
      font-weight: 600;
      margin-bottom: 1rem;
      text-align: center;
      position: relative;
    }
    h2::after {
      content: '';
      width: 60px;
      height: 4px;
      background: var(--accent-color);
      display: block;
      margin: 0.5rem auto 0;
      border-radius: 2px;
    }

    /* Skills list */
    .skills-list {
      display: flex;
      flex-wrap: wrap;
      gap: 0.75rem;
      justify-content: center;
      list-style: none;
      padding: 0;
    }
    .skills-list li {
      background: #fff;
      padding: 0.6rem 1rem;
      border-radius: 30px;
      font-size: 0.95rem;
      box-shadow: 0 2px 8px var(--shadow-color);
      transition: transform 0.2s;
    }
    .skills-list li:hover {
      transform: translateY(-3px);
    }

    /* Certifications list */
    .cert-list {
      max-width: 600px;
      margin: 0 auto;
      list-style: none;
      padding: 0;
    }
    .cert-list li {
      background: #fff;
      margin: 0.5rem 0;
      padding: 0.75rem 1rem;
      border-radius: 8px;
      box-shadow: 0 2px 8px var(--shadow-color);
      font-size: 0.95rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    /* Grid layout for cards (projects & competitions) */
    .cards-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 1.5rem;
      margin-top: 2rem;
    }
    .card {
      background: var(--card-bg);
      border-radius: 12px;
      padding: 1.5rem;
      box-shadow: 0 4px 15px var(--shadow-color);
      display: flex;
      flex-direction: column;
      justify-content: space-between;
      transition: transform 0.2s, box-shadow 0.2s;
    }
    .card:hover {
      transform: translateY(-5px);
      box-shadow: 0 6px 20px var(--shadow-color);
    }
    .card h4 {
      font-size: 1.25rem;
      margin-bottom: 0.75rem;
      font-weight: 600;
    }
    .card p {
      flex-grow: 1;
      font-size: 0.95rem;
    }
    .card .btn {
      background: var(--primary-color);
      color: #fff;
      padding: 0.5rem 1rem;
      border-radius: 30px;
      text-align: center;
      font-size: 0.9rem;
      align-self: flex-start;
      margin-top: 1rem;
      transition: background 0.2s, transform 0.2s;
    }
    .card .btn:hover {
      background: var(--accent-color);
      transform: translateY(-2px);
    }

    /* Experience & Education lists */
    .detail-list {
      list-style: none;
      padding: 0;
      max-width: 800px;
      margin: 0 auto;
    }
    .detail-list li {
      margin-bottom: 1rem;
      font-size: 0.95rem;
    }
    .detail-list h3 {
      font-size: 1.1rem;
      margin-bottom: 0.5rem;
      font-weight: 600;
    }
    .detail-list ul {
      list-style: disc inside;
      padding-left: 1rem;
    }

    /* Contact icons */
    .contact-links {
      display: flex;
      justify-content: center;
      gap: 1.5rem;
      margin-top: 1.5rem;
    }
    .contact-links a img {
      width: 36px;
      height: 36px;
      filter: drop-shadow(0 2px 5px var(--shadow-color));
      transition: transform 0.2s;
    }
    .contact-links a img:hover {
      transform: scale(1.1);
    }

    /* Footer styling */
    footer {
      text-align: center;
      font-size: 0.9rem;
      padding: 1.5rem 0;
      color: var(--dark-gray);
      border-top: 1px solid #e0e0e0;
      background: #fff;
      margin-top: 3rem;
    }
  </style>
</head>
<body>
  <!-- Hero Section -->
  <div class="hero">
    <h1>Sriram Rampelli</h1>
    <p>AI Engineer | Generative AI | LLMs | Computer Vision | Data Engineering</p>
    <p>
      Master’s in Computer Science (Dec 2024) – Lawrence Technological University | F1 Visa (seeks sponsorship)<br/>
      <a href="#contact" class="btn">Let’s Connect</a>
    </p>
  </div>

  <div class="container">
    <!-- About Section -->
    <section id="about">
      <h2>About Me</h2>
      <p>
        I’m an AI/ML Engineer with a Master’s in Computer Science who excels at building and fine-tuning large language models and vision-language systems—often on limited local hardware. By leveraging techniques such as 4-bit quantization, LoRA, and QLoRA adapters, I make state-of-the-art models run efficiently on an NVIDIA 3050 Ti. My projects span RAG pipelines with Hugging Face, Flask-based healthcare chatbots analyzing DICOM images, and end-to-end deployment on constrained GPUs.
      </p>
      <p>
        At Wipro Technologies, I designed ML-driven monitoring frameworks that reduced system errors by 35%. As a Research Assistant at Lawrence Tech (May 2024 – Dec 2024), I fine-tuned LLaMA &amp; BioBERT for clinical NLP and published my thesis at IEEE CCWC 2025. I thrive at the intersection of research and production—balancing model performance with hardware constraints to deliver impactful AI solutions.
      </p>
    </section>

    <!-- Skills Section -->
    <section id="skills">
      <h2>Core Skills &amp; Technologies</h2>
      <ul class="skills-list">
        <li>Python (NumPy, Pandas, scikit-learn)</li>
        <li>PyTorch &amp; TensorFlow</li>
        <li>Hugging Face Transformers</li>
        <li>4-bit Quantization, LoRA, QLoRA</li>
        <li>LangChain &amp; LlamaIndex (RAG Pipelines)</li>
        <li>Computer Vision (CLIP, TinyLlama-VLM)</li>
        <li>Flask &amp; FastAPI Deployment</li>
        <li>Docker &amp; Kubernetes Basics</li>
        <li>SQL, PostgreSQL &amp; Vector DBs (FAISS, Pinecone)</li>
        <li>AWS (S3, EC2, Lambda)</li>
        <li>CI/CD (GitHub Actions, Jenkins)</li>
      </ul>
    </section>

    <!-- Certifications Section -->
    <section id="certifications">
      <h2>Certifications</h2>
      <ul class="cert-list">
        <li>
          <span>NVIDIA-Certified Associate: Generative AI &amp; LLMs</span>
          
        </li>
        <li>
          <span>Oracle Cloud Infrastructure 2024 Generative AI Certified Professional</span>
        
        </li>
      </ul>
    </section>

    <!-- Competitions Section -->
    <section id="competitions">
      <h2>Competitions</h2>
      <div class="cards-grid">
        <!-- RSNA 2024 Lumbar Spine Classification Card -->
        <div class="card">
          <h4>RSNA 2024 Lumbar Spine Classification</h4>
          <p>
            Contributed to the RSNA 2024 competition by developing a convolutional neural network to classify lumbar spine degenerative conditions. Leveraged data augmentation, ensemble learning, and optimized inference on limited-GPU hardware to achieve over 92% accuracy. All code—preprocessing, model training, and evaluation—is available in the GitHub repository.
          </p>
          <p><strong>Tech:</strong> PyTorch, Keras, NumPy, OpenCV, Docker, AWS S3.</p>
          <a href="https://github.com/sriram7737/RSNA2024" class="btn" target="_blank">View On Github</a>
        </div>
      </div>
    </section>

    <!-- Projects Section -->
    <section id="projects">
      <h2>Highlighted AI/ML Projects</h2>
      <div class="cards-grid">
        <!-- 1. TinyLlama-VLM-LoRA -->
        <div class="card">
          <h4>TinyLlama-VLM-LoRA</h4>
          <p>
            A vision-language model fine-tuned from TinyLlama (1.1B) using LoRA adapters on Flickr30k image-caption pairs. Integrates a frozen CLIP ViT encoder to convert image features into “vision tokens” for TinyLlama, enabling zero-shot captioning. Evaluation scripts include BLEU, ROUGE, F1, and perplexity.
          </p>
          <p><strong>Tech:</strong> TinyLlama, LoRA, CLIP (ViT-Base), PyTorch, Hugging Face Transformers.</p>
          <a href="https://github.com/sriram7737/TinyLlama-VLM-LoRA" class="btn" target="_blank">View on GitHub</a>
        </div>

        <!-- 2. RESEARCH_OF_AI_IN_HEALTHCARE -->
        <div class="card">
          <h4>RESEARCH_OF_AI_IN_HEALTHCARE</h4>
          <p>
            A curated set of literature reviews, experiment scripts, and Jupyter notebooks exploring AI applications in healthcare—ranging from medical image segmentation to NLP for clinical notes and predictive modeling for patient outcomes.
          </p>
          <p><strong>Tech:</strong> Python, Jupyter Notebooks, TensorFlow, scikit-learn, OpenCV, medical imaging libraries.</p>
          <a href="https://github.com/sriram7737/RESEARCH_OF_AI_IN_HEALTHACARE" class="btn" target="_blank">View on GitHub</a>
        </div>

        <!-- 3. AI-Call-Center-Prototype-Faster-Whisper-TinyLLaMA-Demo -->
        <div class="card">
          <h4>AI Call Center Prototype (Faster-Whisper &amp; TinyLLaMA)</h4>
          <p>
            Demonstrates real-time audio transcription via Faster Whisper integrated with TinyLLaMA to generate context-aware responses. Simulates an AI-powered call-center agent: transcribing customer speech, interpreting intent with TinyLLaMA, and returning automated replies.
          </p>
          <p><strong>Tech:</strong> Faster Whisper, TinyLLaMA, PyTorch, Flask, WebSocket streaming.</p>
          <a href="https://github.com/sriram7737/AI-Call-Center-Prototype-Faster-Whisper-TinyLLaMA-Demo" class="btn" target="_blank">View on GitHub</a>
        </div>

        <!-- 4. TRASHPRED- -->
        <div class="card">
          <h4>TRASHPRED</h4>
          <p>
            A transformer-based RGB image classifier to distinguish recyclable vs. non-recyclable items. Trained on a custom waste-image dataset, achieving 92%+ accuracy. Includes data augmentation pipelines and inference scripts deployed via Hugging Face.
          </p>
          <p><strong>Tech:</strong> PyTorch, Hugging Face Transformers, FastAPI, AWS S3 (data storage).</p>
          <a href="https://github.com/sriram7737/TRASHPRED-" class="btn" target="_blank">View on GitHub</a>
        </div>

        <!-- 5. Multi-Source-Data-Analytics-Chatbot -->
        <div class="card">
          <h4>Multi-Source Data Analytics Chatbot</h4>
          <p>
            A Flask-based chatbot that ingests CSV, Excel, PDF, DOCX, JSON, XML, images, and DICOM files—generating histograms, bar charts, pie charts; performing sentiment analysis, summarization, and prescription parsing. Integrated with a fine-tuned GPT-2 model for open-domain Q&amp;A.
          </p>
          <p><strong>Tech:</strong> Python, Flask, PyTorch, GPT-2, OpenAI API, DICOM processing, pandas, matplotlib.</p>
          <a href="https://github.com/sriram7737/Multi-Source-Data-Analytics-Chatbot" class="btn" target="_blank">View on GitHub</a>
        </div>

        <!-- 6. openai_poetry_app -->
        <div class="card">
          <h4>OpenAI Poetry App</h4>
          <p>
            A web application that generates custom poetry using OpenAI’s GPT-3/4 models. Users input prompts and receive stylistically coherent poems. Includes an interactive front end for prompt refinement and a feedback loop for continuous model improvements.
          </p>
          <p><strong>Tech:</strong> OpenAI API, Streamlit, Python, Docker.</p>
          <a href="https://github.com/sriram7737/openai_poetry_app" class="btn" target="_blank">View on GitHub</a>
        </div>

        <!-- 7. Chatbot (Corrected) -->
        <div class="card">
          <h4>AI Healthcare Chatbot</h4>
          <p>
            A Flask-based AI Chatbot for healthcare applications. It answers general medical queries via GPT-2 and Wikipedia, and features a prescription-analysis module that uses <code>en_sci_md</code> to extract structured data (e.g., patient DOB, medications, dosages) from prescription PDFs. Also supports voice input via a speech-to-text interface and generates visual summaries (charts for vitals or medication usage).
          </p>
          <p><strong>Tech:</strong> Flask, Python, spaCy, NLTK, PyTorch (GPT-2), <code>en_sci_md</code>, SpeechRecognition, Pandas, Matplotlib.</p>
          <a href="https://github.com/sriram7737/Chatbot" class="btn" target="_blank">View on GitHub</a>
        </div>
      </div>
    </section>

    <!-- Experience Section -->
    <section id="experience">
      <h2>Professional Experience</h2>
      <ul class="detail-list">
        <li>
          <h3>AI Intern – BCG GenAI Job Simulation | Feb 2025</h3>
          <ul>
            <li>Developed an AI-powered financial chatbot that automated SEC 10-K data extraction, reducing manual effort by 40%.</li>
            <li>Implemented NLP-based structured data extraction using spaCy and pandas.</li>
            <li>Automated financial sentiment analysis, increasing decision-making efficiency by 25% for financial teams.</li>
            <li>Explored retrieval-augmented solutions aligned with RAG principles to support dynamic query responses.</li>
          </ul>
        </li>
        <li>
          <h3>Research Assistant – Lawrence Technological University | May 2024 – Dec 2024</h3>
          <ul>
            <li>Developed an LLM-powered healthcare chatbot integrating fine-tuned LLaMA &amp; enhanced BioBERT, improving medical Q&amp;A accuracy by 23%.</li>
            <li>Designed custom data pipelines to handle noisy clinical text, boosting OCR-based medical-condition recognition by 35% on local hardware (NVIDIA 3050 Ti) via 4-bit quantization and LoRA adapters.</li>
            <li>Published thesis at IEEE CCWC 2025:  
              <a href="https://doi.org/10.1109/CCWC62904.2025.10903815" target="_blank">“Empowering Healthcare Data Systems with an Innovative Chatbot Application Utilizing Python and Advanced Generative AI Models”</a>.
            </li>
            <li>Investigated vector-based retrieval techniques to enhance chatbot performance.</li>
          </ul>
        </li>
        <li>
          <h3>Project Engineer – Wipro Technologies | Nov 2021 – Dec 2022</h3>
          <ul>
            <li>Developed an ML-driven anomaly detection system, reducing system log errors by 35%.</li>
            <li>Optimized system performance by 27% through an ML-driven monitoring framework.</li>
            <li>Managed 300+ test procedures &amp; 100+ Agile sprints, ensuring high-quality releases.</li>
          </ul>
        </li>
      </ul>
    </section>

    <!-- Education & Publications Section -->
    <section id="education">
      <h2>Education &amp; Publications</h2>
      <ul class="detail-list">
        <li>
          <h3>Master of Science in Computer Science | Lawrence Technological University | Dec 2024</h3>
          <ul>
            <li><strong>Relevant Coursework:</strong> Deep Learning, NLP, Computer Vision, Data Mining, Advanced Algorithms.</li>
            <li><strong>Thesis / Publication:</strong>  
              Rampelli, S. (2025). <em>Empowering Healthcare Data Systems with an Innovative Chatbot Application Utilizing Python and Advanced Generative AI Models.</em>  
              Presented at IEEE CCWC 2025.  
              <a href="https://doi.org/10.1109/CCWC62904.2025.10903815" target="_blank">doi:10.1109/CCWC62904.2025.10903815</a>
            </li>
          </ul>
        </li>
      </ul>
    </section>

    <!-- Contact Section -->
    <section id="contact">
      <h2>Get in Touch</h2>
      <p>
        I’m actively seeking AI/ML engineering roles (F1 Visa, open to sponsorship). If you’re building generative AI products, vision-language models, or data pipelines, let’s chat!
      </p>
      <div class="contact-links">
        <a href="mailto:sriramrampelli15@gmail.com" title="Email">
          <img src="https://unpkg.com/simple-icons@v8/icons/gmail.svg" alt="Email Icon" />
        </a>
        <a href="https://github.com/sriram7737" target="_blank" title="GitHub">
          <img src="https://unpkg.com/simple-icons@v8/icons/github.svg" alt="GitHub Icon" />
        </a>
        <a href="https://www.linkedin.com/in/sriram-rampelli/" target="_blank" title="LinkedIn">
          <img src="https://unpkg.com/simple-icons@v8/icons/linkedin.svg" alt="LinkedIn Icon" />
        </a>
        <a href="https://huggingface.co/sriram7737" target="_blank" title="Hugging Face">
          <img src="https://unpkg.com/simple-icons@v8/icons/huggingface.svg" alt="Hugging Face Icon" />
        </a>
      </div>
    </section>

    <!-- Footer -->
    <footer>
      <p>© 2025 Sriram Rampelli. Built with <span style="color: #e25555;">❤</span> for generative AI &amp; data science.</p>
      <p><small>Last updated: June 2025</small></p>
    </footer>
  </div>

  <script>
    // IntersectionObserver to fade in sections on scroll
    document.addEventListener('DOMContentLoaded', () => {
      const sections = document.querySelectorAll('section');
      const observer = new IntersectionObserver(
        entries => {
          entries.forEach(entry => {
            if (entry.isIntersecting) {
              entry.target.classList.add('visible');
            }
          });
        },
        { threshold: 0.15 }
      );
      sections.forEach(section => observer.observe(section));
    });
  </script>
</body>
</html>
